{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30d44e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "luv dis app bt r many bugs\n",
      "app sux download waste time negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import emoji\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define a broader sentiment-based emoji mapping\n",
    "emoji_sentiment_mapping = {\n",
    "    \"😃\": \"positive\",\n",
    "    \"😊\": \"positive\",\n",
    "    \"😁\": \"positive\",\n",
    "    \"😄\": \"positive\",\n",
    "    \"😍\": \"positive\",\n",
    "    \"😎\": \"positive\",\n",
    "    \"🥰\": \"positive\",\n",
    "    \"❤️\": \"positive\",\n",
    "    \"👍\": \"positive\",\n",
    "    \n",
    "    \"😔\": \"negative\",\n",
    "    \"😞\": \"negative\",\n",
    "    \"😟\": \"negative\",\n",
    "    \"😢\": \"negative\",\n",
    "    \"😠\": \"negative\",\n",
    "    \"😡\": \"negative\",\n",
    "    \"👎\": \"negative\",\n",
    "    \n",
    "    \"😐\": \"neutral\",\n",
    "    \"😕\": \"neutral\",\n",
    "    \"😶\": \"neutral\",\n",
    "    \"😑\": \"neutral\",\n",
    "    \n",
    "    \"😂\": \"joyful\",\n",
    "    \"🤣\": \"joyful\",\n",
    "    \"😆\": \"joyful\",\n",
    "    \n",
    "    \"😒\": \"confused\",\n",
    "    \"🙄\": \"confused\",\n",
    "    \"😪\": \"confused\",\n",
    "    \n",
    "    # Add more emojis and sentiment labels as needed\n",
    "}\n",
    "\n",
    "def convert_emoji_to_sentiment(emoji_char):\n",
    "    return emoji_sentiment_mapping.get(emoji_char, \"\")\n",
    "\n",
    "def clean_google_play_reviews(reviews):\n",
    "    cleaned_reviews = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    for review in reviews:\n",
    "        # Remove URLs\n",
    "        review = re.sub(r'http\\S+', '', review)\n",
    "        \n",
    "        # Extract emojis and their sentiment labels\n",
    "        emojis = [c for c in review if c in emoji_sentiment_mapping]\n",
    "        emoji_sentiments = [convert_emoji_to_sentiment(emoji) for emoji in emojis]\n",
    "        review = ''.join([c for c in review if c not in emoji_sentiment_mapping])\n",
    "        \n",
    "        # Tokenize the review into words\n",
    "        words = word_tokenize(review.lower())  # Convert to lowercase\n",
    "        \n",
    "        # Remove punctuation, special characters, and numbers\n",
    "        words = [re.sub(r'[^a-zA-Z]', '', word) for word in words if word.isalpha()]\n",
    "        \n",
    "        # Remove stopwords\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "        \n",
    "        # Reconstruct the cleaned review\n",
    "        cleaned_review = ' '.join(words)\n",
    "        \n",
    "        # Add emoji sentiments as words back to the cleaned review\n",
    "        cleaned_review += ' ' + ' '.join(emoji_sentiments)\n",
    "        \n",
    "        # Remove extra spaces and append to the cleaned_reviews list\n",
    "        cleaned_reviews.append(cleaned_review.strip())\n",
    "    \n",
    "    return cleaned_reviews\n",
    "\n",
    "# Example usage:\n",
    "dirty_reviews = [\n",
    "    \"Luv dis app ❤️ it's gr8! bt there r 2 many bugs 🐛🐜\",\n",
    "    \"This app sux, don't download it. Waste of time 😡\",\n",
    "]\n",
    "\n",
    "cleaned_reviews = clean_google_play_reviews(dirty_reviews)\n",
    "for review in cleaned_reviews:\n",
    "    print(review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1babb94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Luv dis app   gr bt r   many bug ❤🐛🐜\n",
      "app sux download Waste time 😡\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import emoji\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the spaCy model for English\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_emojis(text):\n",
    "    return ''.join(c for c in text if c in emoji.EMOJI_DATA)\n",
    "\n",
    "def clean_google_play_reviews(reviews):\n",
    "    cleaned_reviews = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    for review in reviews:\n",
    "        # Remove URLs\n",
    "        review = re.sub(r'http\\S+', '', review)\n",
    "        \n",
    "        # Extract emojis and store them as key factors\n",
    "        emojis = extract_emojis(review)\n",
    "        key_factors = emojis.replace(\":\", \" \")  # Replace ':' in emoji names with spaces\n",
    "        review = re.sub(r':\\S+:', '', review)  # Remove emojis\n",
    "        \n",
    "        # Tokenize the review into words\n",
    "        words = review.split()\n",
    "        \n",
    "        # Join the words back into a sentence\n",
    "        review = ' '.join(words)\n",
    "        \n",
    "        # Remove punctuation, special characters, and numbers\n",
    "        review = re.sub(r'[^a-zA-Z\\s]', '', review)\n",
    "        \n",
    "        # Remove stopwords and perform lemmatization\n",
    "        doc = nlp(review)\n",
    "        words = [token.lemma_ for token in doc if token.lemma_ not in stop_words]\n",
    "        \n",
    "        # Reconstruct the cleaned review\n",
    "        cleaned_review = ' '.join(words)\n",
    "        \n",
    "        # Add key factors back to the cleaned review\n",
    "        cleaned_review += ' ' + key_factors\n",
    "        \n",
    "        # Remove extra spaces and append to the cleaned_reviews list\n",
    "        cleaned_reviews.append(cleaned_review.strip())\n",
    "    \n",
    "    return cleaned_reviews\n",
    "\n",
    "# Example usage:\n",
    "dirty_reviews = [\n",
    "    \"Luv dis app ❤️ it's gr8! bt there r 2 many bugs 🐛🐜\",\n",
    "    \"This app sux, don't download it. Waste of time 😡\",\n",
    "]\n",
    "\n",
    "cleaned_reviews = clean_google_play_reviews(dirty_reviews)\n",
    "for review in cleaned_reviews:\n",
    "    print(review)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7583e25b",
   "metadata": {},
   "source": [
    "# Final Data Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9f71be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "luv dis app bt r many bugs\n",
      "app sux download waste time angry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import emoji\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define a mapping of emojis to sentiment labels\n",
    "emoji_sentiment_mapping = {\n",
    "    \"😃\": \"happy\",\n",
    "    \"😔\": \"sad\",\n",
    "    \"😡\": \"angry\",\n",
    "    \"❤️\": \"love\",\n",
    "    \"👍\": \"positive\",\n",
    "    \"👎\": \"negative\",\n",
    "    # Add more emojis and sentiment labels as needed\n",
    "}\n",
    "\n",
    "def convert_emoji_to_sentiment(emoji_char):\n",
    "    return emoji_sentiment_mapping.get(emoji_char, \"\")\n",
    "\n",
    "def clean_google_play_reviews(reviews):\n",
    "    cleaned_reviews = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    for review in reviews:\n",
    "        # Remove URLs\n",
    "        review = re.sub(r'http\\S+', '', review)\n",
    "        \n",
    "        # Extract emojis and their sentiment labels\n",
    "        emojis = [c for c in review if c in emoji_sentiment_mapping]\n",
    "        emoji_sentiments = [convert_emoji_to_sentiment(emoji) for emoji in emojis]\n",
    "        review = ''.join([c for c in review if c not in emoji_sentiment_mapping])\n",
    "        \n",
    "        # Tokenize the review into words\n",
    "        words = word_tokenize(review.lower())  # Convert to lowercase\n",
    "        \n",
    "        # Remove punctuation, special characters, and numbers\n",
    "        words = [re.sub(r'[^a-zA-Z]', '', word) for word in words if word.isalpha()]\n",
    "        \n",
    "        # Remove stopwords\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "        \n",
    "        # Reconstruct the cleaned review\n",
    "        cleaned_review = ' '.join(words)\n",
    "        \n",
    "        # Add emoji sentiments as words back to the cleaned review\n",
    "        cleaned_review += ' ' + ' '.join(emoji_sentiments)\n",
    "        \n",
    "        # Remove extra spaces and append to the cleaned_reviews list\n",
    "        cleaned_reviews.append(cleaned_review.strip())\n",
    "    \n",
    "    return cleaned_reviews\n",
    "\n",
    "# Example usage:\n",
    "dirty_reviews = [\n",
    "    \"Luv dis app ❤️ it's gr8! bt there r 2 many bugs 🐛🐜\",\n",
    "    \"This app sux, don't download it. Waste of time 😡\",\n",
    "]\n",
    "\n",
    "cleaned_reviews = clean_google_play_reviews(dirty_reviews)\n",
    "for review in cleaned_reviews:\n",
    "    print(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe02fca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
